{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import re\n",
    "from pandas.errors import ParserError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "cadena_ser = pd.read_csv(\"data/cadena_ser.csv\")\n",
    "cadena_ser.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
    "cadena_ser.to_csv(\"data/cadena_ser_links_bup.csv\")\n",
    "old_links = cadena_ser.url.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6g/vz95ncc10qb5p6zp51qtwbc40000gn/T/ipykernel_96569/4070638796.py:5: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(chrome_options=options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 new links will be parsed\n"
     ]
    }
   ],
   "source": [
    "new_links = pd.DataFrame(columns=[\"pos\",\"url\",\"crawl_day\"])\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(chrome_options=options)\n",
    "\n",
    "url = \"https://www.cadenaser.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "page_source = driver.page_source\n",
    "\n",
    "soup = BeautifulSoup(page_source, \"html.parser\") #lxml to be solved\n",
    "\n",
    "articles = soup.find_all(\"article\")\n",
    "\n",
    "for n,article in enumerate(articles):\n",
    "    l = []\n",
    "    for a in article.findAll(\"a\"):\n",
    "        try:\n",
    "            href = \"https://www.cadenaser.com{0}\".format(a[\"href\"])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    pos = n\n",
    "\n",
    "    l.append([pos,href,date.today()])\n",
    "    df_ = pd.DataFrame(l,columns=[\"pos\",\"url\",\"crawl_day\"])\n",
    "    new_links = pd.concat([new_links,df_],axis=0)\n",
    "\n",
    "new_links.drop_duplicates(inplace=True)\n",
    "new_links.reset_index(inplace=True,drop=True)\n",
    "\n",
    "for col,row in new_links.iterrows():\n",
    "    if row[\"url\"] in old_links:\n",
    "        new_links.drop(col,inplace=True)\n",
    "\n",
    "cadena_ser = pd.concat([cadena_ser,new_links],axis=0)\n",
    "cadena_ser.drop_duplicates(inplace=True)\n",
    "cadena_ser.reset_index(inplace=True,drop=True)\n",
    "\n",
    "print(\"{0} new links will be parsed\".format(len(new_links)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.DataFrame(columns=[\"fecha\",\"programa\",\"seccion\",\"tags\",\"tags_2\",\"loc\",\"titulo\",\"titulo_2\",\"subtiulo\",\"texto\",\"url\",\"pos\",\"crawl_day\"])\n",
    "\n",
    "for col,row in new_links.iterrows():\n",
    "    try:\n",
    "        l=[]\n",
    "        url = row[\"url\"]\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        head = soup.find(\"head\")\n",
    "        body = soup.find(\"body\")\n",
    "        article = soup.find(\"article\")\n",
    "\n",
    "        seccion = article.find(\"a\",class_=\"bcrumb\").text\n",
    "        titulo = article.header.find(\"h1\").text\n",
    "        subtitulo = article.header.find(\"h2\").text\n",
    "        fecha = pd.to_datetime(head.find(\"meta\",property=\"article:published_time\")[\"content\"]).date().isoformat()\n",
    "        seccion = head.find_all(\"meta\",property=\"article:tag\")[0][\"content\"]\n",
    "        programa = article.header.find(\"a\").text\n",
    "\n",
    "        lista_tags =list(head.find_all(\"meta\",property=\"article:tag\"))\n",
    "        \n",
    "        tags = []\n",
    "        for i in lista_tags:\n",
    "            tags.append(i[\"content\"])\n",
    "\n",
    "        tags = \", \".join(tags)\n",
    "        \n",
    "        titulo_2 = head.find(\"meta\", property=\"og:title\")[\"content\"]\n",
    "        loc = body.find(\"p\",class_=\"loc\").text\n",
    "        texto = body.find(\"div\",class_=\"cnt-txt\").text\n",
    "\n",
    "        lista_tags_2 = body.find(\"div\",class_=\"tags\").find_all(\"li\")\n",
    "\n",
    "        tags_2 = []\n",
    "        for i in lista_tags:\n",
    "            tags_2.append(i[\"content\"])\n",
    "\n",
    "        tags_2 = \", \".join(tags_2)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    l.append([fecha, programa, seccion, tags, tags_2, loc, titulo, titulo_2, subtitulo, texto, row[\"url\"], row[\"pos\"],date.today()])\n",
    "    df_ = pd.DataFrame(l,columns=[\"fecha\",\"programa\",\"seccion\",\"tags\",\"tags_2\",\"loc\",\"titulo\",\"titulo_2\",\"subtiulo\",\"texto\",\"url\",\"pos\",\"crawl_day\"])\n",
    "    df_full = pd.concat([df_full,df_], axis=0)\n",
    "\n",
    "df_full.url.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cadena_ser = pd.read_csv(\"data/cadena_ser_full.csv\")\n",
    "df_cadena_ser.drop(\"Unnamed: 0\",axis=1,inplace=True)\n",
    "df_cadena_ser.reset_index(inplace=True,drop=True)\n",
    "df_cadena_ser.to_csv(\"data/cadena_ser_full_bup.csv\")\n",
    "\n",
    "df_cadena_ser = pd.concat([df_cadena_ser,df_full],axis=0)\n",
    "df_cadena_ser.reset_index(inplace=True,drop=True)\n",
    "df_cadena_ser.to_csv(\"data/cadena_ser_full_full.csv\")\n",
    "\n",
    "# ACTUALIZANDO OLD LINKS\n",
    "cadena_ser.to_csv(\"data/cadena_ser.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('leads')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "618d3f638ea503cbbee3308cf1918aa542d28a00dc1a5419a264ab2d9a576c6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
